/**
 * Leads Database Module ‚Äî Postgres (replaces leads.json)
 *
 * ‡πÉ‡∏ä‡πâ DATABASE_URL ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏ö‡∏ô Railway
 * Schema: leads table with JSONB data + indexed columns
 * Fallback: ‡∏ñ‡πâ‡∏≤ DB ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏° ‚Üí ‡πÉ‡∏ä‡πâ file ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
 *
 * Interface ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô loadLeads/saveLeads/updateLead ‡πÄ‡∏î‡∏¥‡∏° ‚Äî ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏Ñ‡πà storage layer
 */

import pg from 'pg';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const DATA_DIR = path.join(__dirname, '..', 'data');
const LEADS_FILE = path.join(DATA_DIR, 'leads.json');

const { Pool } = pg;
let pool = null;
let dbReady = false;

// ============================================================
// Init
// ============================================================

async function initLeadsDB() {
  const connectionString = process.env.DATABASE_URL;
  if (!connectionString) {
    console.log('[DB-LEADS] No DATABASE_URL ‚Äî using file fallback');
    return false;
  }

  try {
    pool = new Pool({
      connectionString,
      ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false,
      max: 5,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 5000,
    });

    // Test connection
    await pool.query('SELECT 1');

    // Try to create schema ‚Äî may fail on read-only poolers (Supabase transaction mode)
    try {
      await pool.query(`
        CREATE TABLE IF NOT EXISTS leads (
          id SERIAL PRIMARY KEY,
          place_id TEXT UNIQUE,
          email TEXT,
          domain TEXT,
          status TEXT DEFAULT 'new',
          data JSONB NOT NULL,
          created_at TIMESTAMPTZ DEFAULT NOW(),
          updated_at TIMESTAMPTZ DEFAULT NOW()
        );

        CREATE TABLE IF NOT EXISTS leads_meta (
          key TEXT PRIMARY KEY,
          value JSONB NOT NULL,
          updated_at TIMESTAMPTZ DEFAULT NOW()
        );

        CREATE INDEX IF NOT EXISTS idx_leads_status ON leads(status);
        CREATE INDEX IF NOT EXISTS idx_leads_email ON leads(email);
        CREATE INDEX IF NOT EXISTS idx_leads_domain ON leads(domain);
        CREATE INDEX IF NOT EXISTS idx_leads_place_id ON leads(place_id);
      `);
      console.log('[DB-LEADS] ‚úÖ Schema created/verified');
    } catch (ddlErr) {
      // DDL failed (read-only connection) ‚Äî check if tables already exist
      console.log(`[DB-LEADS] ‚ö†Ô∏è DDL failed (${ddlErr.message.slice(0, 60)}) ‚Äî checking if tables exist...`);
      try {
        await pool.query('SELECT 1 FROM leads LIMIT 1');
        await pool.query('SELECT 1 FROM leads_meta LIMIT 1');
        console.log('[DB-LEADS] ‚úÖ Tables already exist ‚Äî proceeding without DDL');
      } catch {
        // Tables really don't exist and we can't create them
        throw new Error('Tables do not exist and cannot create (read-only): ' + ddlErr.message);
      }
    }

    dbReady = true;
    console.log('[DB-LEADS] ‚úÖ PostgreSQL leads DB ready');

    // Skip DB‚Üîfile sync on startup ‚Äî DB has millions of rows (duplicated data),
    // file is the source of truth for bulk reads. DB used for stats/writes only.

    return true;
  } catch (err) {
    console.error('[DB-LEADS] ‚ùå Init failed:', err.message);
    dbReady = false;
    return false;
  }
}

// ============================================================
// Restore: Postgres ‚Üí JSON file (on deploy / startup)
// ============================================================

async function restoreToFile() {
  try {
    const [leadsResult, domainsResult, lastRunResult] = await Promise.all([
      pool.query('SELECT data FROM leads ORDER BY id'),
      pool.query("SELECT value FROM leads_meta WHERE key = 'processedDomains'"),
      pool.query("SELECT value FROM leads_meta WHERE key = 'lastRun'"),
    ]);

    const leads = leadsResult.rows.map(r => r.data);
    const processedDomains = domainsResult.rows[0]?.value || [];
    const lastRun = lastRunResult.rows[0]?.value || null;

    // Check if file has MORE leads (local changes not yet synced)
    let fileCount = 0;
    try {
      const fileData = JSON.parse(fs.readFileSync(LEADS_FILE, 'utf-8'));
      fileCount = fileData.leads?.length || 0;
    } catch { /* no file */ }

    if (fileCount > leads.length) {
      console.log(`[DB-LEADS] ‚ö†Ô∏è File has ${fileCount} leads, DB has ${leads.length} ‚Äî keeping file (local has more)`);
      // Sync file ‚Üí DB instead
      await migrateFromJSON();
      return;
    }

    const data = { leads, processedDomains, lastRun };
    const content = JSON.stringify(data, null, 2);

    if (!fs.existsSync(DATA_DIR)) fs.mkdirSync(DATA_DIR, { recursive: true });
    const fd = fs.openSync(LEADS_FILE, 'w');
    fs.writeSync(fd, content);
    fs.fsyncSync(fd);
    fs.closeSync(fd);

    console.log(`[DB-LEADS] ‚úÖ Restored ${leads.length} leads from Postgres to leads.json`);
  } catch (err) {
    console.error('[DB-LEADS] ‚ùå Restore to file failed:', err.message);
  }
}

// ============================================================
// Migration: JSON ‚Üí Postgres (one-time)
// ============================================================

async function migrateFromJSON() {
  try {
    if (!fs.existsSync(LEADS_FILE)) {
      console.log('[DB-LEADS] No leads.json to migrate');
      return;
    }

    const fileData = JSON.parse(fs.readFileSync(LEADS_FILE, 'utf-8'));
    const leads = fileData.leads || [];
    if (leads.length === 0) {
      console.log('[DB-LEADS] leads.json is empty, nothing to migrate');
      return;
    }

    console.log(`[DB-LEADS] üîÑ Migrating ${leads.length} leads from JSON to Postgres...`);

    let migrated = 0;
    const batchSize = 50;

    for (let i = 0; i < leads.length; i += batchSize) {
      const batch = leads.slice(i, i + batchSize);
      const values = [];
      const placeholders = [];

      for (let j = 0; j < batch.length; j++) {
        const lead = batch[j];
        const offset = j * 5;
        placeholders.push(`($${offset + 1}, $${offset + 2}, $${offset + 3}, $${offset + 4}, $${offset + 5})`);
        values.push(
          lead.place_id || `auto_${Date.now()}_${i + j}`,
          lead.email || null,
          lead.domain || null,
          lead.status || 'new',
          JSON.stringify(lead)
        );
      }

      await pool.query(`
        INSERT INTO leads (place_id, email, domain, status, data)
        VALUES ${placeholders.join(', ')}
        ON CONFLICT (place_id) DO UPDATE SET
          data = EXCLUDED.data,
          email = EXCLUDED.email,
          domain = EXCLUDED.domain,
          status = EXCLUDED.status,
          updated_at = NOW()
      `, values);

      migrated += batch.length;
    }

    // Save processedDomains to meta
    if (fileData.processedDomains?.length) {
      await pool.query(`
        INSERT INTO leads_meta (key, value, updated_at)
        VALUES ('processedDomains', $1, NOW())
        ON CONFLICT (key) DO UPDATE SET value = $1, updated_at = NOW()
      `, [JSON.stringify(fileData.processedDomains)]);
    }

    // Save lastRun to meta
    if (fileData.lastRun) {
      await pool.query(`
        INSERT INTO leads_meta (key, value, updated_at)
        VALUES ('lastRun', $1, NOW())
        ON CONFLICT (key) DO UPDATE SET value = $1, updated_at = NOW()
      `, [JSON.stringify(fileData.lastRun)]);
    }

    console.log(`[DB-LEADS] ‚úÖ Migrated ${migrated} leads to Postgres`);
  } catch (err) {
    console.error('[DB-LEADS] ‚ùå Migration failed:', err.message);
  }
}

// ============================================================
// Core CRUD ‚Äî same interface as file-based
// ============================================================

/**
 * Load all leads (replaces JSON loadLeads)
 * @returns {{ leads: Array, processedDomains: Array, lastRun: string|null }}
 */
async function loadLeads() {
  // Always use file for bulk reads ‚Äî DB has millions of rows (duplicated data),
  // loading all via SELECT is too slow. DB used for writes/stats/single-lead ops only.
  return loadLeadsFile();
}

/**
 * Save all leads (replaces JSON saveLeads)
 * @param {{ leads: Array, processedDomains?: Array, lastRun?: string }} data
 */
async function saveLeads(data) {
  // Always save to file ‚Äî DB has duplicated data, file is source of truth
  saveLeadsFile(data);
}

/**
 * Update a single lead (efficient ‚Äî doesn't rewrite all leads)
 * @param {string} identifier - place_id, domain, or email
 * @param {object} updates - fields to merge
 * @returns {boolean}
 */
async function updateLead(identifier, updates) {
  if (!dbReady) return updateLeadFile(identifier, updates);

  try {
    // Find the lead
    const { rows } = await pool.query(`
      SELECT id, data FROM leads
      WHERE place_id = $1 OR domain = $1 OR email = $1
      LIMIT 1
    `, [identifier]);

    if (rows.length === 0) return false;

    const lead = { ...rows[0].data, ...updates };

    await pool.query(`
      UPDATE leads SET
        data = $1,
        email = $2,
        domain = $3,
        status = $4,
        updated_at = NOW()
      WHERE id = $5
    `, [JSON.stringify(lead), lead.email || null, lead.domain || null, lead.status || 'new', rows[0].id]);

    return true;
  } catch (err) {
    console.error('[DB-LEADS] updateLead error:', err.message);
    return updateLeadFile(identifier, updates);
  }
}

/**
 * Save a single lead (upsert by place_id)
 */
async function saveLead(lead) {
  if (!dbReady) return;

  try {
    const placeId = lead.place_id || `auto_${Date.now()}`;
    await pool.query(`
      INSERT INTO leads (place_id, email, domain, status, data)
      VALUES ($1, $2, $3, $4, $5)
      ON CONFLICT (place_id) DO UPDATE SET
        data = $5,
        email = $2,
        domain = $3,
        status = $4,
        updated_at = NOW()
    `, [placeId, lead.email || null, lead.domain || null, lead.status || 'new', JSON.stringify(lead)]);
  } catch (err) {
    console.error('[DB-LEADS] saveLead error:', err.message);
  }
}

/**
 * Check if domain is already processed
 */
async function isDomainProcessed(domain) {
  if (!dbReady) return false;

  try {
    const { rows } = await pool.query(
      'SELECT 1 FROM leads WHERE domain = $1 LIMIT 1',
      [domain]
    );
    return rows.length > 0;
  } catch {
    return false;
  }
}

/**
 * Get leads count by status
 */
async function getLeadStats() {
  if (!dbReady) return null;

  try {
    // JS-level 3s timeout ‚Äî DB has millions of rows, COUNT GROUP BY is slow
    const result = await Promise.race([
      pool.query('SET statement_timeout = 3000').then(() =>
        pool.query('SELECT status, COUNT(*) as count FROM leads GROUP BY status')
      ),
      new Promise((_, reject) => setTimeout(() => reject(new Error('timeout')), 3500))
    ]);
    const stats = {};
    result.rows.forEach(r => { stats[r.status] = parseInt(r.count); });
    return stats;
  } catch {
    return null;
  }
}

// ============================================================
// File fallback ‚Äî ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏£
// ============================================================

function loadLeadsFile() {
  try {
    return JSON.parse(fs.readFileSync(LEADS_FILE, 'utf-8'));
  } catch {
    return { leads: [], processedDomains: [], lastRun: null };
  }
}

function saveLeadsFile(data) {
  const content = JSON.stringify(data, null, 2);
  const fd = fs.openSync(LEADS_FILE, 'w');
  fs.writeSync(fd, content);
  fs.fsyncSync(fd);
  fs.closeSync(fd);
}

function updateLeadFile(identifier, updates) {
  const data = loadLeadsFile();
  const idx = data.leads.findIndex(l =>
    (l.place_id && l.place_id === identifier) ||
    (l.domain && l.domain === identifier) ||
    (l.email && l.email === identifier)
  );
  if (idx >= 0) {
    Object.assign(data.leads[idx], updates);
    saveLeadsFile(data);
    return true;
  }
  return false;
}

// ============================================================
// Status
// ============================================================

function isDBReady() {
  return dbReady;
}

function getStatus() {
  return {
    dbReady,
    hasPool: !!pool,
    hasDatabaseUrl: !!process.env.DATABASE_URL,
  };
}

/**
 * Raw query ‚Äî use existing pool (which has write access)
 */
async function rawQuery(sql, params = []) {
  if (!dbReady || !pool) throw new Error('DB not ready');
  return pool.query(sql, params);
}

export {
  initLeadsDB,
  loadLeads,
  saveLeads,
  saveLead,
  updateLead,
  isDomainProcessed,
  getLeadStats,
  migrateFromJSON,
  isDBReady,
  getStatus,
  rawQuery,
};

export default {
  initLeadsDB,
  loadLeads,
  saveLeads,
  saveLead,
  updateLead,
  isDomainProcessed,
  getLeadStats,
  migrateFromJSON,
  isDBReady,
  getStatus,
  rawQuery,
};
